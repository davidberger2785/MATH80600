{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction √† Pytorch",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "YzqKR9-uQ6v1",
        "sWNp8sRWKY_3",
        "Ygv1EKglKhYr",
        "a_Z950euCzVA",
        "PZR2Rjc7DNcl",
        "gBycMitzPVNJ",
        "zQi6nvXwQQxB",
        "yRK8V_85QjPO",
        "UgDO-GNSQcTI",
        "JV0ZM07IThcn",
        "N-KYVPIITh_i",
        "jPoJBIARXWMQ",
        "0DD48UBLGRzo",
        "ceggKx4XKdPW",
        "N0KEO2HBH_IZ",
        "UgrRRJAjYv57",
        "gZ-V5JCLsqsR",
        "6OJIIJP-ZJzh",
        "mgGHtgisZJ2H",
        "smFTSR7Ne2tZ",
        "7ikwjrcpkcnQ",
        "Jf6Q4cv-lm4k",
        "hTSqw4muM7xC",
        "MwuVVhsqRbGp",
        "-yuRqq0-ZK7H"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidberger2785/MATH80600/blob/main/Introduction_%C3%A0_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mavSS3fDPelJ"
      },
      "source": [
        "# Semaine 4: Introduction √† Pytorch\n",
        "\n",
        "\n",
        "**Auteurs**:\n",
        "\n",
        "David Berger (davidberger2785 [at] gmail [dot] com)\n",
        "\n",
        "Le pr√©sent atelier s'est (grandement) inspir√© des ateliers de: \n",
        "1. Mang Qu et Zhaocheng Zhu dans le cadre du cours MATH 80600A √† l'hiver 2021 √† HEC\n",
        "2. Chin-Wei Huang dans le cadre du cours IFT 6135 √† l'hiver 2019 √† l'Universit√© de Montr√©al.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "\n",
        "Dans cet atelier, nous allons apprendre comment utliser la biblioth√®que Pytorch et, accessoirement, comment impl√©menter des r√©seaux de neurones √† l'aide cette derni√®re. \n",
        "\n",
        "L'ensemble du code ci-bas peut √™tre ex√©cut√© directement sur Google Colab. Utiliser cette plate-forme pr√©sente plusieurs avantages, le principal √©tant de proposer aux usagers.√®res l'acc√®s √† un GPU, ce qui acc√©l√®re grandement le temps de calcul pour des t√¢ches plus lourdes.\n",
        "\n",
        "\n",
        "Avant d'ex√©cuter l'ensemble des commandes de ce tutoriel, assurez-vous que d'utiliser un GPU. Pour ce faire:\n",
        "1. S√©lectionnez *Ex√©cution¬†&gt;¬†Modifier le type d'ex√©cution*.\n",
        "2. Dans le menu d√©roulant *Acc√©l√©rateur mat√©riel*, s√©lectionnez l'option *GPU*."
      ],
      "metadata": {
        "id": "GGpDCzb_SxGC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzqKR9-uQ6v1"
      },
      "source": [
        "# 2. Installation des biblioth√®ques\n",
        "\n",
        "Installons les biblioth√®ques d'usage en [langage Python](https://www.youtube.com/watch?v=RpOzFBSwSLc)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from __future__ import print_function"
      ],
      "metadata": {
        "id": "YpFSaHcbYXj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, nous installons quelques biblioth√®ques propres √† Pytorch."
      ],
      "metadata": {
        "id": "6eLrqzjrYcDy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy6WrZejQjX1"
      },
      "source": [
        "!pip install -q torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFl3AxEQweQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfEhtUIRAOP"
      },
      "source": [
        "V√©rifier qu'un GPU est bien disponible pour le notebook peut s'av√©rer une bonne id√©e. Pour ce tutoriel, la sortie associ√©e devrait est True.\n",
        "\n",
        "Bien qu'il soit possible d'avoir acc√®s √† un GPU avec Colab, notez que toute commande, ou op√©ration, n'implique pas n√©cessairement l'utilisation d'un GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjd7eKpcQ_zK"
      },
      "source": [
        "torch.cuda.is_available()  # Afin de v√©rifier si un GPU est disponible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWNp8sRWKY_3"
      },
      "source": [
        "# 3.0 Rudiments sur les tenseurs\n",
        "\n",
        "En apprentissage profond, les donn√©es sont repr√©sent√©es √† l'aide de [tenseurs](https://fr.wikipedia.org/wiki/Tenseur) que l'on pourrait grossi√®rement consid√©rer comme une g√©n√©ralisation des matrices. Dans cette section, nous r√©viserons quelques commandes fondamentales sur les tenseurs en Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygv1EKglKhYr"
      },
      "source": [
        "## 3.1 Une image de chat\n",
        "\n",
        "T√©l√©chargeons dans premier temps une image et r√©prensatons-la sous la forme d'un tenseur √† l'aide de Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/b/b6/Felis_catus-cat_on_snow.jpg -O cat_winter.jpg"
      ],
      "metadata": {
        "id": "ubjaq7_dqkRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhSqAWIL7RL"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "np_image = np.array(Image.open(\"cat_winter.jpg\"))\n",
        "image = torch.as_tensor(np_image)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty0bAttdL9EY"
      },
      "source": [
        "Par convention:\n",
        "- La **dimension** ref√®re √† l'un des axes du tenseur.\n",
        "- La **taille** ref√®re √† la longeur d'un axe choisi pour une dimension choisie d'un tenseur.\n",
        "- L'**index** ref√®re √† une coordonn√©e particuli√®re du tenseur.\n",
        "\n",
        "√Ä titre d'exemple, l'image ci-dessus pr√©sente trois dimensions. Les deux premi√®res dimensions ont des tailles de 2000 et 3000 respectivement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blLeqjosL_QA"
      },
      "source": [
        "print(\"Nombre de dimensions:\", image.ndim)\n",
        "print(\"Taille de chaque dimension:\", image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions 3.1**\n",
        "\n",
        "1. √Ä quoi est associ√©e √† la troisi√®me dimension du tenseur dans l'image ci-haut?\n",
        "\n",
        "2. Trouvez une fa√ßon de visualiser l'une de ces dimensions."
      ],
      "metadata": {
        "id": "Srt4JnwcwDDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R√©ponses 3.1**\n",
        "\n",
        "Aux trois canaux RGB. On peut visualiser l'un des trois canaux en fixant simplement l'un des indices."
      ],
      "metadata": {
        "id": "pCbrO0YQwMsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image[:, :, 0]) \n"
      ],
      "metadata": {
        "id": "bCeF97Kmwljk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M2RA8BTEEF4"
      },
      "source": [
        "**Op√©rations arithm√©tiques**\n",
        "\n",
        "Les op√©rations sur les tenseurs sont analogues √† celles rencontr√©es dans un cours d'introduction en alg√®bre lin√©aire o√π l'accent est mis sur les op√©rations matricielles. Par exemple, pour chacun des pixels de l'image t√©l√©charg√©e, nous pouvons calculer la valeur moyenne de la troisi√®me dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts3imnSXMDSd"
      },
      "source": [
        "channel_mean = image.float().mean(dim=2)\n",
        "print(channel_mean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIh5SB-G-_Yx"
      },
      "source": [
        "La moyenne calcul√©e, nous pouvons visualiser la nouvelle image, o√π toute couleur devrait √™tre √©vacu√©e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypTTxhnD9C_z"
      },
      "source": [
        "plt.imshow(channel_mean,  cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7BG4NTfMGWn"
      },
      "source": [
        "**Coordonn√©es**\n",
        "\n",
        "Nous pouvons √©galement couper l'image en quatre parties disjointes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKHz1cqHMKf9"
      },
      "source": [
        "y_dim, x_dim = int(image.shape[0] / 2), int(image.shape[1] / 2)\n",
        "\n",
        "crop_up_left = image[:y_dim, :x_dim, :]\n",
        "crop_up_right = image[:y_dim, x_dim:, :]\n",
        "crop_bottom_left = image[y_dim:, :x_dim, :]\n",
        "crop_bottom_right = image[ y_dim:, x_dim:, :]\n",
        "\n",
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(crop_up_left)\n",
        "axarr[1,0].imshow(crop_bottom_left)\n",
        "axarr[0,1].imshow(crop_up_right)\n",
        "axarr[1,1].imshow(crop_bottom_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSjgNWWKMM23"
      },
      "source": [
        "**Transposition**\n",
        "\n",
        "Nous pouvons transposer les deux premiers axes de l'image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msca9rpIMO-H"
      },
      "source": [
        "transposition = image.transpose(0, 1)   # Transposition du premier (0) et du deuxi√®me (1) axes\n",
        "plt.imshow(transposition)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U58JGQFzMUl4"
      },
      "source": [
        "**Changement de dimensions**\n",
        "\n",
        "Nous pouvons r√©duire les dimensions d'un tenseur. Ce genre de manipulation est typique si nous voulons effectuer une op√©ration sur plusieurs axes de fa√ßon simultann√©e comme nous le ferons √† la Section 7.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNGmu9hRMWRB"
      },
      "source": [
        "flat = image.flatten(0, 1)\n",
        "print(flat.shape)\n",
        "plt.imshow(flat[:10, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 D√©laissons les chats\n",
        "\n",
        "D√©laissons les images de chats et travaillons sur des objets plus abstraits. Dans cette section, nous pr√©senterons en rafale quelques op√©rations utiles sur les tenseurs qu'il est possible d'effectuer en Pytorch."
      ],
      "metadata": {
        "id": "a_Z950euCzVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.1 Initialisation d'un tenseur al√©atoire"
      ],
      "metadata": {
        "id": "PZR2Rjc7DNcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(5, 3)"
      ],
      "metadata": {
        "id": "BS4B6faOC5XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour initialisation √† partir d'une distribution choisie, on peut se r√©f√©rer √† [cette page](https://pytorch.org/docs/stable/torch.html#in-place-random-sampling) sur le site de Pytorch."
      ],
      "metadata": {
        "id": "5tbdtab7DVgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu, sigma = 0, 1\n",
        "torch.Tensor(5, 3).normal_(mu, sigma)"
      ],
      "metadata": {
        "id": "lxoPfQsuC6rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ou encore en effectuant cette commande:"
      ],
      "metadata": {
        "id": "ADY_YIA1FgwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(mu, sigma, size=(5, 3))"
      ],
      "metadata": {
        "id": "05Ts1Qx4FWB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.2 Construction de tenseurs particuliers\n",
        "\n",
        "Il est possible de construire des tenseurs uniquement constitu√©s de 0 ou de 1."
      ],
      "metadata": {
        "id": "gBycMitzPVNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longueur = 5\n",
        "torch.ones(longueur), torch.zeros(longueur)"
      ],
      "metadata": {
        "id": "ovpVrZdWPVXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.3 Type d'un tenseur\n",
        "\n",
        "Dans certains cas, le type de tenseur est important. Plus de d√©tails sur les types [ici](https://pytorch.org/docs/master/tensors.html)!\n"
      ],
      "metadata": {
        "id": "zQi6nvXwQQxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.Tensor([[1, 3], [2, 9]])\n",
        "print(z.type())\n",
        "print(z.numpy().dtype)\n",
        "\n",
        "z_ = torch.LongTensor([[1, 3], [2, 9]])\n",
        "print(z_.type())\n",
        "print(z_.numpy().dtype)"
      ],
      "metadata": {
        "id": "CLfb3gHtQi4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.4 Manipulations arithm√©tiques\n",
        "\n",
        "Plusieurs op√©rations arithm√©tiques sont possibles."
      ],
      "metadata": {
        "id": "yRK8V_85QjPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 2).uniform_(0, 1)\n",
        "y = x ** torch.eye(2)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "vYDPtLCFQjYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et surprenemment simple √† ex√©cuter."
      ],
      "metadata": {
        "id": "t53r4OwHQjg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(2, 2)\n",
        "y = x / torch.sqrt(noise ** 2)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "kMLY2EDpQjne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.5 Diffusion\n",
        "\n",
        "Nous pouvons par exemple additionner √† la premi√®re dimension dimension d'un tenseur $\\mathbf{x}$ un tenseur $\\mathbf{y}$ dont les dimensions sont identiques aux dimensions subs√©quentes de $\\mathbf{x}$. "
      ],
      "metadata": {
        "id": "UgDO-GNSQcTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "y = x + torch.arange(2)\n",
        "print(y)\n",
        "# print(x + torch.arange(5))"
      ],
      "metadata": {
        "id": "awRZEfFBThTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.6 Manipulation des dimensions\n",
        "\n",
        "Apprendre √† manipuler convenablement les dimensions des tenseurs est un art perdu. Franchement, le meilleur truc est de pratiquer, et de se souvenir que pareilles manipulations existent!"
      ],
      "metadata": {
        "id": "JV0ZM07IThcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randn(2, 3, 4)\n",
        "print(\"Taille originale: \", y.size())\n",
        "print(\"Mixer les deux premi√®res dimension: \", y.view(-1, 4).size()) \n",
        "\n",
        "indice = 1\n",
        "print(\"Ajout de dimension √† l'indice: \", y.view(-1, 4).unsqueeze(indice).size()) \n",
        "print(y.view(-1, 4).unsqueeze(1).unsqueeze(2).unsqueeze(3).squeeze().size()) # cette commande est franchement d√©gueulasse"
      ],
      "metadata": {
        "id": "Z09idyNbThk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et apprendre √† transposer est une bonne id√©e √©galement!"
      ],
      "metadata": {
        "id": "RZBkIH5kThtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.transpose(0, 1).size())\n",
        "print(y.transpose(1, 2).size())\n",
        "print(y.transpose(0, 1).transpose(1, 2).size())\n",
        "print(y.permute(1, 2, 0).size())"
      ],
      "metadata": {
        "id": "AoIKAQFtTh3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.7 Concat√©nation de tenseurs"
      ],
      "metadata": {
        "id": "N-KYVPIITh_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimension originale:\", y.shape)\n",
        "\n",
        "k = 2 # dimension dans laquelle nous voulons concatener\n",
        "print(\"Concat√©nation sur la ki√®me dimension:\", torch.cat([y, y], dim=k).size())\n",
        "\n",
        "# stack empile les tenseurs dans une nouvelle dimension\n",
        "print(\"Empilons les tenseurs avec stack:\", torch.stack([y, y], 0).size())"
      ],
      "metadata": {
        "id": "aIHe48JPXWDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.8 Indexation avanc√©e"
      ],
      "metadata": {
        "id": "jPoJBIARXWMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_idx = torch.arange(1, -1, -1).long()\n",
        "print(rev_idx)\n",
        "print(y[rev_idx].size())   # pour inverser les tenseurs de la premiere dimension"
      ],
      "metadata": {
        "id": "ahSWEsT_XWTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, [torch.gather](https://pytorch.org/docs/1.9.1/generated/torch.gather.html) peut √™tre une fonctionnalit√© utile."
      ],
      "metadata": {
        "id": "nKjbF_p3XWbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.arange(12).view(3,4)   # equivalent √† reshape\n",
        "print(v)\n",
        "print(v.shape)\n",
        "\n",
        "# Supposons que l'on veut retourner les element [1], [6] et [8]\n",
        "print(torch.gather(v, 1, torch.tensor([1,2,0]).long().unsqueeze(1)))"
      ],
      "metadata": {
        "id": "vDcSnoppXWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###3.2.9 Navigueur des CPUs aux GPUs (et vice versa)"
      ],
      "metadata": {
        "id": "0DD48UBLGRzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
        "print(x)\n",
        "x = x.cuda()\n",
        "print(x)\n",
        "x = x.cpu()\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Az02cpr9b0yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceggKx4XKdPW"
      },
      "source": [
        "##3.3 Remarque rapide sur les fonctions en Pytorch\n",
        "\n",
        "Enfin, il y a vraiment pleins d'op√©rations plus sophistiqu√©es qui ont √©t√© impl√©ment√©es par le pass√©. La r√®gle du pouce: si vous √™tes capable d'y donner un nom, elle existe en Pytorch! Si vous comprenez bien ce que la fonction fait, cela ne vaut pas la peine de l'impl√©menter √† la mitaine. Surtout que la plupart des fonctions sont robustes aux probl√®mes d'instabilit√© num√©rique...\n",
        "\n",
        "Par exemple, supposons que $ùê∞$ est un tenseur de taille $d$. La fonction $\\text{softmax}(ùê∞)$ est d√©finie ainsi:\n",
        "\n",
        "\n",
        "$$\\\\ \\text{softmax}(ùê∞)_i := \\frac{\\exp(ùê∞_i)}{\\sum_{k=1}^d \\exp(ùê∞_k)},$$\n",
        "\n",
        "o√π $\\exp (\\cdot)$ est la fonction exponentielle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgUVQ4lVKdPW"
      },
      "source": [
        "\n",
        "w = torch.tensor([1., 2., 3., 4., 5.])\n",
        "w_cuda = w.cuda()\n",
        "\n",
        "w_exp = w.exp()\n",
        "w_sum = w_exp.sum()\n",
        "w_exp/w_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqPWm5fcKdPX"
      },
      "source": [
        "Naturellement, la fonction softmax est directement [impl√©ment√©e en Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0YU5kcKdPX"
      },
      "source": [
        "torch.softmax(w, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.0 Calcul du gradient et diff√©rentiation automatique\n",
        "\n",
        "Estimer les param√®tres r√©gissant les r√©seaux de neurones est souvent une t√¢che complexe. La fonction de perte √† optimiser n'admettant pas une solution analytique, la descente de gradient s'av√®re une technique indispensable pour estimer les param√®tres de pareilles architectures. Or, avant l'arriv√©e des biblioth√®ques d'apprentissage profond, chercheur.e.s et praticien.ne.s se voyaient oblig√©s d'expliciter l'expression du gradient pour chaque param√®tre du r√©seau. Si cet exercice est plus ou moins p√©nible pour des MLPs (amusez-vous √† coder un MLPs seulement en Numpy!), il se complique lorsque les architectures se complexifient. Pensez √† un ResNet ou encore √† un LSTM.\n",
        "\n",
        "En ce sens, le calcul du gradient par diff√©rentiation automatique est un outil pr√©cieux qui vous permettra, avec un peu de pratique, d'impl√©menter et de d√©velopper des architectures complexes. Par contre, il est n√©cessaire de bien saisir comment la diff√©rentiation automatique proc√®de. \n",
        "\n",
        "La pr√©sente section vise √† introduire la diff√©rentation automatique selon Pytorch. Elle peut para√Ætre r√©barbative √† prime √† bord, mais les b√©n√©fices √† moyens et longs termes en valent la peine.\n",
        "\n",
        "Enfin, le mat√©riel pr√©sent√© ici s'inspire principalement de deux sources √† savoir [le tutoriel d'introduction √† Autograd par Pytorch](http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py) et [une introduction √† la m√©canime d'Autograd par Pytorch](http://pytorch.org/docs/master/notes/autograd.html)."
      ],
      "metadata": {
        "id": "N0KEO2HBH_IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Ce qu'il faut savoir\n",
        "\n",
        "Les r√©seaux de neurones peuvent √™tre consid√©r√©s comme une succession de fonctions, lesquelles sont, ou pas, embriqu√©es les unes dans les autres. Chaque fonction est d√®s lors d√©finie gr√¢ce √† un ensemble de param√®tres dont les valeurs sont m√©moris√©es √† l'aide de tenseurs.\n",
        "\n",
        "Comme nous l'avons pr√©sent√© lors du deuxi√®me cours, l'entra√Ænement d'un r√©seau de neurones peut √™tre d√©fini en deux √©tapes distinctes:\n",
        "\n",
        "1. **Propagation du message vers l'avant**: o√π, en fonction du mod√®le estim√©, une pr√©diction d'une issue est faite en fonction d'un ensemble d'entr√©e.\n",
        "\n",
        "2. **R√©tro propagation vers l'arri√®re**: o√π, en fonction de l'issue estim√©e lors de la premi√®re √©tape et de la pr√©cision de cette mesure par rapport √† sa valeur r√©elle, une correction des param√®tres du mod√®le est effectu√©e.\n",
        "\n",
        "Dans cette section, nous pr√©sentons en quelques √©tapes simples comment utiliser la diff√©rentiation automatique pour entra√Æner un r√©seau de neurone avec Pytorch. Cette section n'introduit aucunement la m√©canique derri√®re chacune des fonctions utilis√©es. "
      ],
      "metadata": {
        "id": "UgrRRJAjYv57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Initialisation du mod√®le\n",
        "\n",
        "Lors de la s√©ances portant sur les CNNs, nous avons bri√®vement introduit les ResNets. Nous proposons donc de t√©l√©charger le mod√®le ResNet18 √† partir de torch.vision. Une technique d'optimisation est √©galement choisie, comme par exemple la descente stochastique de gradient, avec un pas d'apprentissage de 0,1. Enfin, on opte pour une fonction de perte bas√©e sur l'erreur quadratique moyenne (MSE)."
      ],
      "metadata": {
        "id": "gZ-V5JCLsqsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)   # importation de ResNet18\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.1e1) \n",
        "loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Ir7SXWfTdLbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aux fins de l'exercices, nous cr√©ons un tenseur initialis√© de fa√ßon al√©atoire et l'issue, ou √©tiquette, qui lui est associ√©e."
      ],
      "metadata": {
        "id": "JuWH0sJlr7fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(1, 3, 64, 64)   # generation d'un tenseur aleatoire\n",
        "labels = torch.rand(1, 1000)   # generation d'une issue"
      ],
      "metadata": {
        "id": "4auO8GOWsHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 Propagation vers l'avant\n",
        "\n",
        "Par apr√®s, nous propageons l'information du message vers l'avant tel que d√©crit bri√®vement au point 1."
      ],
      "metadata": {
        "id": "6OJIIJP-ZJzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data)    # propagation du message vers l'avant"
      ],
      "metadata": {
        "id": "WrHQbyFOd2l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.3 Calcul de la fonction de perte \n",
        "\n",
        "Une fois la pr√©diction calcul√©e, nous calculons l'erreur de pr√©diction en fonction des vraies valeurs (et de la fonction de perte choisie)."
      ],
      "metadata": {
        "id": "mgGHtgisZJ2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = loss(labels, prediction)"
      ],
      "metadata": {
        "id": "ysyw9vv-fFt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.4 Calcul du gradient via r√©tro propagation\n",
        "\n",
        "L'erreur est alors r√©tro propag√©e √† travers le ResNet18. Pour chaque param√®tre du mod√®le, un gradient est calcul√© et nous pouvons obtenir ces valeurs avec la commande suivante."
      ],
      "metadata": {
        "id": "smFTSR7Ne2tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.backward()"
      ],
      "metadata": {
        "id": "op8jo1b1f092"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.5 Mise √† jour des param√®tres \n",
        "\n",
        "Enfin, la descente de gradient peut √™tre effectu√©e!"
      ],
      "metadata": {
        "id": "7ikwjrcpkcnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "GQby6q5QinrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voil√†! Vous savez maintenant comment utiliser Autograd pour entra√Æner un r√©seau de neurones!"
      ],
      "metadata": {
        "id": "pmd0tI5gsyA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Ce qui vous sera (certainement) utile\n",
        "\n",
        "Dans cette section, nous proposons de comprendre davantage en profondeur le fonctionnement d'Autograd afin d'effectuer la diff√©rentiation automatique. Pour d√©velopper notre intuition, nous d√©laisserons les r√©seaux de neurones et travaillerons plut√¥t avec un ensemble restreint de fonctions."
      ],
      "metadata": {
        "id": "Jf6Q4cv-lm4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialisation et attribut**: Dans un premier temps, nous initialisons deux vecteurs de param√®tres, soit $\\mathbf{a}$ et $\\mathbf{b}$, pour lesquels nous voulons calculer leur gradient."
      ],
      "metadata": {
        "id": "mp1iyLxPuRD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "FB4hQbXnuYeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fonction simple**: Nous d√©finissons une variable $\\mathbf{c}$ laquelle est d√©finie en fonction des vecteurs $\\mathbf{a}$ et $\\mathbf{b}$ ainsi:\n",
        "\n",
        "$$ \\mathbf{c} = 3 \\mathbf{a}^2 - \\mathbf{b}$$."
      ],
      "metadata": {
        "id": "F138C9Ouubs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = 3 * a**2 - b"
      ],
      "metadata": {
        "id": "LccJjwqdvTo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calcul du gradient de fa√ßon analytique**: De fa√ßon similaire √† ce que nous avons pr√©sent√© √† la section pr√©c√©dente, supposons que $\\mathbf{c}$ est l'erreur. Afin d'estimer les param√®tres du r√©seau de neurones, soit $\\mathbf{a}$ et $\\mathbf{b}$, nous devons calculer les d√©riv√©es partielles de $\\mathbf{c}$ en fonction des param√®tres:\n",
        "\n",
        "$$ \\frac{d \\mathbf{c}}{d \\mathbf{a}} = 6 \\mathbf{a}, \\qquad \\frac{d \\mathbf{c}}{d \\mathbf{b}} = -1.$$\n",
        "\n",
        "**Calcul du gradient avec Autograd**: Nous pouvons calculer les expressions ci-haut simplement √† l'aide de la commande .backward().\n"
      ],
      "metadata": {
        "id": "Wr9-meMuvYcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c.sum().backward()"
      ],
      "metadata": {
        "id": "N1FShoD_vYme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et c'est heureux que les valeurs obtenues concordent avec celles d√©riv√©es formellement:"
      ],
      "metadata": {
        "id": "h4rxCCiLzfoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(6 * a == a.grad)\n",
        "print(-1 == b.grad)"
      ],
      "metadata": {
        "id": "WZG07Wp_yk7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Quelles valeurs aurions-nous obtenues si nous avions d√©cid√©, lors de l'initialisation du vecteur $\\mathbf{a}$, de ne pas calculer le gradient pour ce vecteur de param√®tres?"
      ],
      "metadata": {
        "id": "ljh4y_TDvYux"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTSqw4muM7xC"
      },
      "source": [
        "#5.0 Classifieur lin√©aire\n",
        "\n",
        "Dans cette section, nous allons entra√Æner un classifieur lin√©aire plut√¥t na√Øf sur le c√©l√®bre jeu de donn√©es [Iris](https://fr.wikipedia.org/wiki/Iris_de_Fisher). L'id√©e n'est pas d'utiliser des mod√®les sophistiqu√©s, mais de simplement se faire tranquillement la main sur les concepts de diff√©rentiation automtique vus jusqu'√† pr√©sent."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importatation des biblioth√®ques**"
      ],
      "metadata": {
        "id": "6YwRO2BF76xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "g7HsPpuB5noE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pr√©paration des donn√©es**"
      ],
      "metadata": {
        "id": "6LrU-aus8AqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importation des donnes\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# creation des ensemble d'entrainement et de test\n",
        "# toujours une bonne idee de brasser la soupe avant de commencer #shuffle\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "kf.get_n_splits(y)\n",
        "\n",
        "for train_index, test_index in kf.split(y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# transformation des donnees sous la forme de tenseur\n",
        "X_train, X_test = torch.Tensor(X_train), torch.Tensor(X_test)\n",
        "y_train, y_test = torch.Tensor(y_train), torch.Tensor(y_test)"
      ],
      "metadata": {
        "id": "4izyvOC_4kJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Un mod√®le**\n",
        "\n",
        "Dans ce cas-ci, nous allons supposer que les issues suivent le mod√®le suivant:\n",
        "\n",
        "$$ y = \\beta_0 x_0 + \\beta_1 x_1 + \\epsilon,$$\n",
        "o√π $\\epsilon \\sim N(0, 1)$. √âvidemment, cette mod√©lisation n'est pas appropri√©e (comprenez-vous pourquoi?), mais elle fera le boulot pour la suite de l'exemple. \n",
        "\n",
        "Nous pouvons d√®s lors initialiser notre mod√®le avec une classe plut√¥t simple.Enfin, comprendre comment cr√©er une classe en Python est fondamental pour cr√©er des mod√®les plus complexes. Assurez-vous de bien comprendre ce concept."
      ],
      "metadata": {
        "id": "j-cmUkxc8xyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model():\n",
        "  def __init__(self):\n",
        "    self.params = torch.tensor([[0.], [0.]], requires_grad=True)\n",
        "  \n",
        "  def prediction(self, X):\n",
        "    return(torch.mm(X, self.params).squeeze_())"
      ],
      "metadata": {
        "id": "EBsMgQDD4kVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "1. Que pensez-vous de l'initialisation des param√®tres du mod√®le. Est-ce un probl√®me dans ce cas-ci? \n",
        "2.Pouvez-vous imaginer un cas d'esp√®ce o√π ce genre d'initalisation ne serait pas souhaitable?"
      ],
      "metadata": {
        "id": "2wkU1h3BASdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialisation**\n",
        "\n",
        "Nous initialisons par la suite le mod√®le et d√©finissons les hyper param√®tres."
      ],
      "metadata": {
        "id": "s5HWqNKZAKbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl = model()   # initialisation du modele\n",
        "mse = nn.MSELoss()   # fonction de perte choisie\n",
        "\n",
        "# Quelques hyper param√®tres\n",
        "lr = 1e-2   # pas d'apprentissage\n",
        "nb_epoch = int(1e2)   # nombre d'epoques"
      ],
      "metadata": {
        "id": "5fDwX4d13OQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apprentissage**\n",
        "\n",
        "La phase d'entra√Ænement se fait de fa√ßon analogue √† ce que nous avons vu √† la Section."
      ],
      "metadata": {
        "id": "94abzXsOIgHl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9OOBLiOY1BB"
      },
      "source": [
        "mse_train, mse_test = [], []\n",
        "\n",
        "# Apprentissage\n",
        "for epoch in range(nb_epoch):\n",
        "  \n",
        "  # Prediction (voir le module mm dans Pytorch)\n",
        "  y_hat = cl.prediction(X_train)\n",
        "\n",
        "  # Calcul de la fonction de perte (EQM dans ce cas-ci)\n",
        "  loss = mse(y_hat, y_train)\n",
        "  mse_train.append(loss)   # pratique pour un graphe futur\n",
        " \n",
        "  # Calcul du gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # Mise a jour des parametres du modele\n",
        "  cl.params.data = cl.params.data - lr * cl.params.grad\n",
        "  cl.params.grad.zero_()\n",
        "\n",
        "  mse_test.append(mse(y_test, cl.prediction(X_test)))   # pour un graphe futur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, nous pouvons √©tudier rapidement comment le mod√®le se comporte au fil des it√©rations √† l'aide d'un petit graphique."
      ],
      "metadata": {
        "id": "_T_0qjEZI9si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mse_train, label= 'Entra√Ænement')\n",
        "plt.plot(mse_test, label= 'Test')\n",
        "\n",
        "plt.xlabel('Epoques')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "fKFQ5CYgLRQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "1. Est-ce que les courbes ci-haut se comportent de fa√ßon attendue?\n",
        "2. Comment pourrions-nous fixer ce \"probl√®me\"?"
      ],
      "metadata": {
        "id": "QqRfQM4KQ9xZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwuVVhsqRbGp"
      },
      "source": [
        "#6.0 MLP en Pytorch et Skorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGAG7UbRw0-"
      },
      "source": [
        "Dans cette section, nous proposons d'impl√©menter et entra√Æner un MLP sur le jeu de donn√©e [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST). Ce jeu de donn√©es est fameux et consiste √† classer des images des chifres manuscrits.\n",
        "\n",
        "**T√©l√©chargement des donn√©es**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8V13Q9QRkY3"
      },
      "source": [
        "train = torchvision.datasets.MNIST(\"./data\", train=True, download=True)\n",
        "test = torchvision.datasets.MNIST(\"./data\", train=False, download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKY8i-9Ss84"
      },
      "source": [
        "**Visualisation des donn√©es**\n",
        "\n",
        "Afin d'avoir une petite id√©e du jeu de donn√©es en question, nous pouvons visualiser quelques images en entr√©e √† l'aide de notre fonction maison plot_mnist.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mnist(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])"
      ],
      "metadata": {
        "id": "gnUYrp4sU4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egUTRNA5S_gQ"
      },
      "source": [
        "train.labels = [train.classes[target] for target in train.targets]\n",
        "plot_mnist(train.data, train.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQXSiqhdS_It"
      },
      "source": [
        "**Construction de la classe MLP**\n",
        "\n",
        "Nous pouvons construire le MLP √† l'aide de la classe suivante. Si vous √™tes un peu confus.es, ne vous inqui√©tez pas; ce genre de manipulation deviendra rapidement une seconde nature avec un peu d'entra√Ænement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToHnu6quUUYD"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "    super(MLP, self).__init__()\n",
        "    \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, images):\n",
        "    x = images.flatten(1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.softmax(self.fc2(x), dim=-1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La classe construite, nous pouvons initialiser notre mod√®le."
      ],
      "metadata": {
        "id": "VZI--VxtTMMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))"
      ],
      "metadata": {
        "id": "ToPDlp4CTMc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXW7M_JgWdHQ"
      },
      "source": [
        "**Skorch**\n",
        "\n",
        "Dans ce tutoriel, l'entra√Ænement des mod√®les va se faire √† l'aide de [Skorch](https://skorch.readthedocs.io/en/stable/index.html). Cette biblioth√®que permet entres autres d'utiliser des mod√®les impl√©ment√©s en Pytorch et d'effectuer l'entra√Ænement √† l'aide de [Scikit-learn](https://scikit-learn.org/stable/). La phase d'entra√Ænement du MLP diff√®re donc beaucoup de celle que nous avons pr√©sent√© √† la section pr√©c√©dente, o√π la m√©canique d'Autograd √©tait beaucoup plus explicite. M√™me si l'interfarce de Skorch est beaucoup plus convivial, je vous encore fortement √† comprendre et saisir les nuances pr√©sent√©es √† la Section 6."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U skorch"
      ],
      "metadata": {
        "id": "jUdUDx9yRZDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skorch"
      ],
      "metadata": {
        "id": "Jm68y7m1RbkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous faisons la migration du MLP en Skortch et fixons les hyper param√®tres associ√©s."
      ],
      "metadata": {
        "id": "zCZMLxuaVBlD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nxm2ibVEW1"
      },
      "source": [
        "# Hyper param√®tres\n",
        "num_epoch = 20\n",
        "lr = 1e-2\n",
        "\n",
        "# Migration en skorch\n",
        "model = skorch.NeuralNetClassifier(mlp, max_epochs=num_epoch, lr=lr, device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entra√Ænement √† l'aide de Skorch**\n",
        "\n",
        "La phase d'entra√Ænement avec Skorch pr√©sente automatique les performances de pr√©diction pour chacune des √©poques. Une fonction de perte (*loss*) plus faible est pr√©f√©rable et une capacit√© pr√©dictive (*acc*) plus grande est souhaitable."
      ],
      "metadata": {
        "id": "1Vux2_zkTD2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = model.fit(train.data / 255.0, train.targets)"
      ],
      "metadata": {
        "id": "XZwD13ihTING"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFG284ipX8fr"
      },
      "source": [
        "Nous pouvons calculer l'erreur de pr√©diction sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNSoOvJYEGF"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test.mlp_predictions = model.predict(test.data / 255.0)\n",
        "sklearn.metrics.accuracy_score(test.targets, test.mlp_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb33PuLLYTFy"
      },
      "source": [
        "Bon, ce n'est pas fameux... C'est possible d'obtenir de bonnes performances √† l'aide d'un MLP. Par contre, cela demande un peu de travail.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "1. Modifier la classe du MLP pour augmenter sa capacit√©, changer les fonctions d'activations, bref, tout ce qui vous passe par la t√™te afin d'am√©liorer les capacit√©s pr√©dictives du mod√®le.\n",
        "\n",
        "2. Opter pour [une autre technique](https://pytorch.org/docs/stable/optim.html#algorithms) afin d'estimer le gradient peut s'av√©rer, entre autres strat√©gies, une bonne id√©e. Voici un exemple ci-bas montrant comment proc√©der. Familiarisez-vous avec pareille manipulation et essayez d'obtenir une capacit√© pr√©dicitve de plus de 96% sur l'ensemble de test."
      ],
      "metadata": {
        "id": "ogVd06lTgp-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim   # cette bibliothque propose une pletarde d'optimiseurs\n",
        "\n",
        "# initalisation du modele\n",
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))\n",
        "\n",
        "# migration sur Skorch mais avec un nouvel optimiseur\n",
        "model = skorch.NeuralNetClassifier(mlp, optimizer=optim.RMSprop, max_epochs=10,\n",
        "                                   lr=1e-4, device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "model.fit(train.data / 255.0, train.targets)\n",
        "\n",
        "# predictions sur l'ensemble de test\n",
        "test.mlp_predictions = model.predict(test.data / 255.0)\n",
        "test_acc = sklearn.metrics.accuracy_score(test.targets, test.mlp_predictions)\n",
        "\n",
        "print(\"\\n Peformances sur l'ensemble de test: \", test_acc)"
      ],
      "metadata": {
        "id": "qMwMfxCmhM4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sauvegarde du mod√®le**\n",
        "\n",
        "Enfin, c'est une bonne id√©e de sauvegarder notre mod√®le √† la suite de l'entra√Ænement.\n"
      ],
      "metadata": {
        "id": "AlX_CD8uglrk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bip_3kAmY3LG"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"MLP.pkl\", \"wb\") as fout:\n",
        "  pickle.dump(model, fout)\n",
        "with open(\"MLP.pkl\", \"rb\") as fin:\n",
        "  model = pickle.load(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yuRqq0-ZK7H"
      },
      "source": [
        "# 7.0 CNN en Pytorch et Skorch\n",
        "\n",
        "Souvent, utiliser des mod√®les d√©j√† impl√©ment√©s peut s'av√©rer une tr√®s bonne id√©e. Cela sauve beaucoup de temps, entre autres choses... Heureusement, il existe plusieurs mod√®les classiques de CNN d√©j√† impl√©ment√©s dans la biblioth√®que `torchvision`.\n",
        "\n",
        "Dans cette section, nous allons utiliser le mod√®le ResNet-18 (!). Puisque ce mod√®le a √©t√© impl√©ment√© pour classer mille types d'images, nous allons simplement r√©√©crire la derni√®re couche cach√©e pour l'adapter au jeu de donn√©es MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEvxTOmBZnBh"
      },
      "source": [
        "resnet18 = torchvision.models.resnet18()\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))   # overide de la sortie pour l'adapter √† MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVYr-2FEbH9P"
      },
      "source": [
        "Encore une fois, puisque ResNet a √©t√© impl√©ment√© pour traiter des images color√©es, nous allons r√©√©crire les images MNIST sous la forme d'un tenseur comportant trois canaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5xhvVEfbWhl"
      },
      "source": [
        "train.color_data = train.data.unsqueeze(1).expand(-1, 3, -1, -1)\n",
        "test.color_data = test.data.unsqueeze(1).expand(-1, 3, -1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCCXNrEUfDXl"
      },
      "source": [
        "Comme √† la section pr√©c√©dente, nous initialisons notre mod√®le et l'entrainons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnMilF8cfWGr"
      },
      "source": [
        "# hyper parametres\n",
        "num_epoch = 2\n",
        "lr = 1e-1\n",
        "\n",
        "# initialisation\n",
        "resnet = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=num_epoch, lr=lr,\n",
        "    device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "training = resnet.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KVGjdZVNwmg"
      },
      "source": [
        "Sans surprise, et avec tr√®s peu d'effort, ResNet √©crase notre MLP un peu vanille..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZomzNBiLqN"
      },
      "source": [
        "**Mod√®le pr√© entra√Æn√©es** \n",
        "\n",
        "La biblioth√®que `torchvision` [propose des mod√®les pr√© entra√Æn√©s](https://pytorch.org/docs/stable/torchvision/models.html) sur des jeux de donn√©es distincts. Par exemple, dans ce cas-ci, le ResNet que nous allons t√©l√©charg√© a √©t√© entra√Æn√© sur ImageNet. Initialiser notre mod√®le avec ce genre de param√®tres peut s'av√©rer une bonne strat√©gie.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18-eQwAYijhA"
      },
      "source": [
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B20vHsLzbfRR"
      },
      "source": [
        "# migration vers Skorch\n",
        "resnet = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=num_epoch, lr=lr,\n",
        "    device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "training = resnet.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}