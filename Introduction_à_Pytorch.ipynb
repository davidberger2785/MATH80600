{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction à Pytorch",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "YzqKR9-uQ6v1",
        "sWNp8sRWKY_3",
        "Ygv1EKglKhYr",
        "a_Z950euCzVA",
        "PZR2Rjc7DNcl",
        "gBycMitzPVNJ",
        "zQi6nvXwQQxB",
        "yRK8V_85QjPO",
        "UgDO-GNSQcTI",
        "JV0ZM07IThcn",
        "N-KYVPIITh_i",
        "jPoJBIARXWMQ",
        "0DD48UBLGRzo",
        "ceggKx4XKdPW",
        "N0KEO2HBH_IZ",
        "UgrRRJAjYv57",
        "gZ-V5JCLsqsR",
        "6OJIIJP-ZJzh",
        "mgGHtgisZJ2H",
        "smFTSR7Ne2tZ",
        "7ikwjrcpkcnQ",
        "Jf6Q4cv-lm4k",
        "hTSqw4muM7xC",
        "MwuVVhsqRbGp",
        "-yuRqq0-ZK7H"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidberger2785/MATH80600/blob/main/Introduction_%C3%A0_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mavSS3fDPelJ"
      },
      "source": [
        "# Semaine 4: Introduction à Pytorch\n",
        "\n",
        "\n",
        "**Auteurs**:\n",
        "\n",
        "David Berger (davidberger2785 [at] gmail [dot] com)\n",
        "\n",
        "Le présent atelier s'est (grandement) inspiré des ateliers de: \n",
        "1. Mang Qu et Zhaocheng Zhu dans le cadre du cours MATH 80600A à l'hiver 2021 à HEC\n",
        "2. Chin-Wei Huang dans le cadre du cours IFT 6135 à l'hiver 2019 à l'Université de Montréal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "\n",
        "Dans cet atelier, nous allons apprendre comment utliser la bibliothèque Pytorch et, accessoirement, comment implémenter des réseaux de neurones à l'aide cette dernière. \n",
        "\n",
        "L'ensemble du code ci-bas peut être exécuté directement sur Google Colab. Utiliser cette plate-forme présente plusieurs avantages, le principal étant de proposer aux usagers.ères l'accès à un GPU, ce qui accélère grandement le temps de calcul pour des tâches plus lourdes.\n",
        "\n",
        "\n",
        "Avant d'exécuter l'ensemble des commandes de ce tutoriel, assurez-vous que d'utiliser un GPU. Pour ce faire:\n",
        "1. Sélectionnez *Exécution &gt; Modifier le type d'exécution*.\n",
        "2. Dans le menu déroulant *Accélérateur matériel*, sélectionnez l'option *GPU*."
      ],
      "metadata": {
        "id": "GGpDCzb_SxGC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzqKR9-uQ6v1"
      },
      "source": [
        "# 2. Installation des bibliothèques\n",
        "\n",
        "Installons les bibliothèques d'usage en [langage Python](https://www.youtube.com/watch?v=RpOzFBSwSLc)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from __future__ import print_function"
      ],
      "metadata": {
        "id": "YpFSaHcbYXj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, nous installons quelques bibliothèques propres à Pytorch."
      ],
      "metadata": {
        "id": "6eLrqzjrYcDy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy6WrZejQjX1"
      },
      "source": [
        "!pip install -q torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFl3AxEQweQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfEhtUIRAOP"
      },
      "source": [
        "Vérifier qu'un GPU est bien disponible pour le notebook peut s'avérer une bonne idée. Pour ce tutoriel, la sortie associée devrait est True.\n",
        "\n",
        "Bien qu'il soit possible d'avoir accès à un GPU avec Colab, notez que toute commande, ou opération, n'implique pas nécessairement l'utilisation d'un GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjd7eKpcQ_zK"
      },
      "source": [
        "torch.cuda.is_available()  # Afin de vérifier si un GPU est disponible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWNp8sRWKY_3"
      },
      "source": [
        "# 3.0 Rudiments sur les tenseurs\n",
        "\n",
        "En apprentissage profond, les données sont représentées à l'aide de [tenseurs](https://fr.wikipedia.org/wiki/Tenseur) que l'on pourrait grossièrement considérer comme une généralisation des matrices. Dans cette section, nous réviserons quelques commandes fondamentales sur les tenseurs en Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygv1EKglKhYr"
      },
      "source": [
        "## 3.1 Une image de chat\n",
        "\n",
        "Téléchargeons dans premier temps une image et réprensatons-la sous la forme d'un tenseur à l'aide de Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/b/b6/Felis_catus-cat_on_snow.jpg -O cat_winter.jpg"
      ],
      "metadata": {
        "id": "ubjaq7_dqkRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhSqAWIL7RL"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "np_image = np.array(Image.open(\"cat_winter.jpg\"))\n",
        "image = torch.as_tensor(np_image)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty0bAttdL9EY"
      },
      "source": [
        "Par convention:\n",
        "- La **dimension** refère à l'un des axes du tenseur.\n",
        "- La **taille** refère à la longeur d'un axe choisi pour une dimension choisie d'un tenseur.\n",
        "- L'**index** refère à une coordonnée particulière du tenseur.\n",
        "\n",
        "À titre d'exemple, l'image ci-dessus présente trois dimensions. Les deux premières dimensions ont des tailles de 2000 et 3000 respectivement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blLeqjosL_QA"
      },
      "source": [
        "print(\"Nombre de dimensions:\", image.ndim)\n",
        "print(\"Taille de chaque dimension:\", image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions 3.1**\n",
        "\n",
        "1. À quoi est associée à la troisième dimension du tenseur dans l'image ci-haut?\n",
        "\n",
        "2. Trouvez une façon de visualiser l'une de ces dimensions."
      ],
      "metadata": {
        "id": "Srt4JnwcwDDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Réponses 3.1**\n",
        "\n",
        "Aux trois canaux RGB. On peut visualiser l'un des trois canaux en fixant simplement l'un des indices."
      ],
      "metadata": {
        "id": "pCbrO0YQwMsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image[:, :, 0]) \n"
      ],
      "metadata": {
        "id": "bCeF97Kmwljk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M2RA8BTEEF4"
      },
      "source": [
        "**Opérations arithmétiques**\n",
        "\n",
        "Les opérations sur les tenseurs sont analogues à celles rencontrées dans un cours d'introduction en algèbre linéaire où l'accent est mis sur les opérations matricielles. Par exemple, pour chacun des pixels de l'image téléchargée, nous pouvons calculer la valeur moyenne de la troisième dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts3imnSXMDSd"
      },
      "source": [
        "channel_mean = image.float().mean(dim=2)\n",
        "print(channel_mean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIh5SB-G-_Yx"
      },
      "source": [
        "La moyenne calculée, nous pouvons visualiser la nouvelle image, où toute couleur devrait être évacuée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypTTxhnD9C_z"
      },
      "source": [
        "plt.imshow(channel_mean,  cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7BG4NTfMGWn"
      },
      "source": [
        "**Coordonnées**\n",
        "\n",
        "Nous pouvons également couper l'image en quatre parties disjointes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKHz1cqHMKf9"
      },
      "source": [
        "y_dim, x_dim = int(image.shape[0] / 2), int(image.shape[1] / 2)\n",
        "\n",
        "crop_up_left = image[:y_dim, :x_dim, :]\n",
        "crop_up_right = image[:y_dim, x_dim:, :]\n",
        "crop_bottom_left = image[y_dim:, :x_dim, :]\n",
        "crop_bottom_right = image[ y_dim:, x_dim:, :]\n",
        "\n",
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(crop_up_left)\n",
        "axarr[1,0].imshow(crop_bottom_left)\n",
        "axarr[0,1].imshow(crop_up_right)\n",
        "axarr[1,1].imshow(crop_bottom_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSjgNWWKMM23"
      },
      "source": [
        "**Transposition**\n",
        "\n",
        "Nous pouvons transposer les deux premiers axes de l'image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msca9rpIMO-H"
      },
      "source": [
        "transposition = image.transpose(0, 1)   # Transposition du premier (0) et du deuxième (1) axes\n",
        "plt.imshow(transposition)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U58JGQFzMUl4"
      },
      "source": [
        "**Changement de dimensions**\n",
        "\n",
        "Nous pouvons réduire les dimensions d'un tenseur. Ce genre de manipulation est typique si nous voulons effectuer une opération sur plusieurs axes de façon simultannée comme nous le ferons à la Section 7.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNGmu9hRMWRB"
      },
      "source": [
        "flat = image.flatten(0, 1)\n",
        "print(flat.shape)\n",
        "plt.imshow(flat[:10, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Délaissons les chats\n",
        "\n",
        "Délaissons les images de chats et travaillons sur des objets plus abstraits. Dans cette section, nous présenterons en rafale quelques opérations utiles sur les tenseurs qu'il est possible d'effectuer en Pytorch."
      ],
      "metadata": {
        "id": "a_Z950euCzVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.1 Initialisation d'un tenseur aléatoire"
      ],
      "metadata": {
        "id": "PZR2Rjc7DNcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(5, 3)"
      ],
      "metadata": {
        "id": "BS4B6faOC5XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour initialisation à partir d'une distribution choisie, on peut se référer à [cette page](https://pytorch.org/docs/stable/torch.html#in-place-random-sampling) sur le site de Pytorch."
      ],
      "metadata": {
        "id": "5tbdtab7DVgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu, sigma = 0, 1\n",
        "torch.Tensor(5, 3).normal_(mu, sigma)"
      ],
      "metadata": {
        "id": "lxoPfQsuC6rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ou encore en effectuant cette commande:"
      ],
      "metadata": {
        "id": "ADY_YIA1FgwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(mu, sigma, size=(5, 3))"
      ],
      "metadata": {
        "id": "05Ts1Qx4FWB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.2 Construction de tenseurs particuliers\n",
        "\n",
        "Il est possible de construire des tenseurs uniquement constitués de 0 ou de 1."
      ],
      "metadata": {
        "id": "gBycMitzPVNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longueur = 5\n",
        "torch.ones(longueur), torch.zeros(longueur)"
      ],
      "metadata": {
        "id": "ovpVrZdWPVXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.3 Type d'un tenseur\n",
        "\n",
        "Dans certains cas, le type de tenseur est important. Plus de détails sur les types [ici](https://pytorch.org/docs/master/tensors.html)!\n"
      ],
      "metadata": {
        "id": "zQi6nvXwQQxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.Tensor([[1, 3], [2, 9]])\n",
        "print(z.type())\n",
        "print(z.numpy().dtype)\n",
        "\n",
        "z_ = torch.LongTensor([[1, 3], [2, 9]])\n",
        "print(z_.type())\n",
        "print(z_.numpy().dtype)"
      ],
      "metadata": {
        "id": "CLfb3gHtQi4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.4 Manipulations arithmétiques\n",
        "\n",
        "Plusieurs opérations arithmétiques sont possibles."
      ],
      "metadata": {
        "id": "yRK8V_85QjPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 2).uniform_(0, 1)\n",
        "y = x ** torch.eye(2)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "vYDPtLCFQjYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et surprenemment simple à exécuter."
      ],
      "metadata": {
        "id": "t53r4OwHQjg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(2, 2)\n",
        "y = x / torch.sqrt(noise ** 2)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "kMLY2EDpQjne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.5 Diffusion\n",
        "\n",
        "Nous pouvons par exemple additionner à la première dimension dimension d'un tenseur $\\mathbf{x}$ un tenseur $\\mathbf{y}$ dont les dimensions sont identiques aux dimensions subséquentes de $\\mathbf{x}$. "
      ],
      "metadata": {
        "id": "UgDO-GNSQcTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "y = x + torch.arange(2)\n",
        "print(y)\n",
        "# print(x + torch.arange(5))"
      ],
      "metadata": {
        "id": "awRZEfFBThTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.6 Manipulation des dimensions\n",
        "\n",
        "Apprendre à manipuler convenablement les dimensions des tenseurs est un art perdu. Franchement, le meilleur truc est de pratiquer, et de se souvenir que pareilles manipulations existent!"
      ],
      "metadata": {
        "id": "JV0ZM07IThcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randn(2, 3, 4)\n",
        "print(\"Taille originale: \", y.size())\n",
        "print(\"Mixer les deux premières dimension: \", y.view(-1, 4).size()) \n",
        "\n",
        "indice = 1\n",
        "print(\"Ajout de dimension à l'indice: \", y.view(-1, 4).unsqueeze(indice).size()) \n",
        "print(y.view(-1, 4).unsqueeze(1).unsqueeze(2).unsqueeze(3).squeeze().size()) # cette commande est franchement dégueulasse"
      ],
      "metadata": {
        "id": "Z09idyNbThk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et apprendre à transposer est une bonne idée également!"
      ],
      "metadata": {
        "id": "RZBkIH5kThtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.transpose(0, 1).size())\n",
        "print(y.transpose(1, 2).size())\n",
        "print(y.transpose(0, 1).transpose(1, 2).size())\n",
        "print(y.permute(1, 2, 0).size())"
      ],
      "metadata": {
        "id": "AoIKAQFtTh3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.7 Concaténation de tenseurs"
      ],
      "metadata": {
        "id": "N-KYVPIITh_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimension originale:\", y.shape)\n",
        "\n",
        "k = 2 # dimension dans laquelle nous voulons concatener\n",
        "print(\"Concaténation sur la kième dimension:\", torch.cat([y, y], dim=k).size())\n",
        "\n",
        "# stack empile les tenseurs dans une nouvelle dimension\n",
        "print(\"Empilons les tenseurs avec stack:\", torch.stack([y, y], 0).size())"
      ],
      "metadata": {
        "id": "aIHe48JPXWDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.8 Indexation avancée"
      ],
      "metadata": {
        "id": "jPoJBIARXWMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_idx = torch.arange(1, -1, -1).long()\n",
        "print(rev_idx)\n",
        "print(y[rev_idx].size())   # pour inverser les tenseurs de la premiere dimension"
      ],
      "metadata": {
        "id": "ahSWEsT_XWTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, [torch.gather](https://pytorch.org/docs/1.9.1/generated/torch.gather.html) peut être une fonctionnalité utile."
      ],
      "metadata": {
        "id": "nKjbF_p3XWbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.arange(12).view(3,4)   # equivalent à reshape\n",
        "print(v)\n",
        "print(v.shape)\n",
        "\n",
        "# Supposons que l'on veut retourner les element [1], [6] et [8]\n",
        "print(torch.gather(v, 1, torch.tensor([1,2,0]).long().unsqueeze(1)))"
      ],
      "metadata": {
        "id": "vDcSnoppXWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###3.2.9 Navigueur des CPUs aux GPUs (et vice versa)"
      ],
      "metadata": {
        "id": "0DD48UBLGRzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
        "print(x)\n",
        "x = x.cuda()\n",
        "print(x)\n",
        "x = x.cpu()\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Az02cpr9b0yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceggKx4XKdPW"
      },
      "source": [
        "##3.3 Remarque rapide sur les fonctions en Pytorch\n",
        "\n",
        "Enfin, il y a vraiment pleins d'opérations plus sophistiquées qui ont été implémentées par le passé. La règle du pouce: si vous êtes capable d'y donner un nom, elle existe en Pytorch! Si vous comprenez bien ce que la fonction fait, cela ne vaut pas la peine de l'implémenter à la mitaine. Surtout que la plupart des fonctions sont robustes aux problèmes d'instabilité numérique...\n",
        "\n",
        "Par exemple, supposons que $𝐰$ est un tenseur de taille $d$. La fonction $\\text{softmax}(𝐰)$ est définie ainsi:\n",
        "\n",
        "\n",
        "$$\\\\ \\text{softmax}(𝐰)_i := \\frac{\\exp(𝐰_i)}{\\sum_{k=1}^d \\exp(𝐰_k)},$$\n",
        "\n",
        "où $\\exp (\\cdot)$ est la fonction exponentielle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgUVQ4lVKdPW"
      },
      "source": [
        "\n",
        "w = torch.tensor([1., 2., 3., 4., 5.])\n",
        "w_cuda = w.cuda()\n",
        "\n",
        "w_exp = w.exp()\n",
        "w_sum = w_exp.sum()\n",
        "w_exp/w_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqPWm5fcKdPX"
      },
      "source": [
        "Naturellement, la fonction softmax est directement [implémentée en Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0YU5kcKdPX"
      },
      "source": [
        "torch.softmax(w, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.0 Calcul du gradient et différentiation automatique\n",
        "\n",
        "Estimer les paramètres régissant les réseaux de neurones est souvent une tâche complexe. La fonction de perte à optimiser n'admettant pas une solution analytique, la descente de gradient s'avère une technique indispensable pour estimer les paramètres de pareilles architectures. Or, avant l'arrivée des bibliothèques d'apprentissage profond, chercheur.e.s et praticien.ne.s se voyaient obligés d'expliciter l'expression du gradient pour chaque paramètre du réseau. Si cet exercice est plus ou moins pénible pour des MLPs (amusez-vous à coder un MLPs seulement en Numpy!), il se complique lorsque les architectures se complexifient. Pensez à un ResNet ou encore à un LSTM.\n",
        "\n",
        "En ce sens, le calcul du gradient par différentiation automatique est un outil précieux qui vous permettra, avec un peu de pratique, d'implémenter et de développer des architectures complexes. Par contre, il est nécessaire de bien saisir comment la différentiation automatique procède. \n",
        "\n",
        "La présente section vise à introduire la différentation automatique selon Pytorch. Elle peut paraître rébarbative à prime à bord, mais les bénéfices à moyens et longs termes en valent la peine.\n",
        "\n",
        "Enfin, le matériel présenté ici s'inspire principalement de deux sources à savoir [le tutoriel d'introduction à Autograd par Pytorch](http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py) et [une introduction à la mécanime d'Autograd par Pytorch](http://pytorch.org/docs/master/notes/autograd.html)."
      ],
      "metadata": {
        "id": "N0KEO2HBH_IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Ce qu'il faut savoir\n",
        "\n",
        "Les réseaux de neurones peuvent être considérés comme une succession de fonctions, lesquelles sont, ou pas, embriquées les unes dans les autres. Chaque fonction est dès lors définie grâce à un ensemble de paramètres dont les valeurs sont mémorisées à l'aide de tenseurs.\n",
        "\n",
        "Comme nous l'avons présenté lors du deuxième cours, l'entraînement d'un réseau de neurones peut être défini en deux étapes distinctes:\n",
        "\n",
        "1. **Propagation du message vers l'avant**: où, en fonction du modèle estimé, une prédiction d'une issue est faite en fonction d'un ensemble d'entrée.\n",
        "\n",
        "2. **Rétro propagation vers l'arrière**: où, en fonction de l'issue estimée lors de la première étape et de la précision de cette mesure par rapport à sa valeur réelle, une correction des paramètres du modèle est effectuée.\n",
        "\n",
        "Dans cette section, nous présentons en quelques étapes simples comment utiliser la différentiation automatique pour entraîner un réseau de neurone avec Pytorch. Cette section n'introduit aucunement la mécanique derrière chacune des fonctions utilisées. "
      ],
      "metadata": {
        "id": "UgrRRJAjYv57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Initialisation du modèle\n",
        "\n",
        "Lors de la séances portant sur les CNNs, nous avons brièvement introduit les ResNets. Nous proposons donc de télécharger le modèle ResNet18 à partir de torch.vision. Une technique d'optimisation est également choisie, comme par exemple la descente stochastique de gradient, avec un pas d'apprentissage de 0,1. Enfin, on opte pour une fonction de perte basée sur l'erreur quadratique moyenne (MSE)."
      ],
      "metadata": {
        "id": "gZ-V5JCLsqsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)   # importation de ResNet18\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.1e1) \n",
        "loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Ir7SXWfTdLbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aux fins de l'exercices, nous créons un tenseur initialisé de façon aléatoire et l'issue, ou étiquette, qui lui est associée."
      ],
      "metadata": {
        "id": "JuWH0sJlr7fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(1, 3, 64, 64)   # generation d'un tenseur aleatoire\n",
        "labels = torch.rand(1, 1000)   # generation d'une issue"
      ],
      "metadata": {
        "id": "4auO8GOWsHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 Propagation vers l'avant\n",
        "\n",
        "Par après, nous propageons l'information du message vers l'avant tel que décrit brièvement au point 1."
      ],
      "metadata": {
        "id": "6OJIIJP-ZJzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data)    # propagation du message vers l'avant"
      ],
      "metadata": {
        "id": "WrHQbyFOd2l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.3 Calcul de la fonction de perte \n",
        "\n",
        "Une fois la prédiction calculée, nous calculons l'erreur de prédiction en fonction des vraies valeurs (et de la fonction de perte choisie)."
      ],
      "metadata": {
        "id": "mgGHtgisZJ2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = loss(labels, prediction)"
      ],
      "metadata": {
        "id": "ysyw9vv-fFt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.4 Calcul du gradient via rétro propagation\n",
        "\n",
        "L'erreur est alors rétro propagée à travers le ResNet18. Pour chaque paramètre du modèle, un gradient est calculé et nous pouvons obtenir ces valeurs avec la commande suivante."
      ],
      "metadata": {
        "id": "smFTSR7Ne2tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.backward()"
      ],
      "metadata": {
        "id": "op8jo1b1f092"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.5 Mise à jour des paramètres \n",
        "\n",
        "Enfin, la descente de gradient peut être effectuée!"
      ],
      "metadata": {
        "id": "7ikwjrcpkcnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "GQby6q5QinrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voilà! Vous savez maintenant comment utiliser Autograd pour entraîner un réseau de neurones!"
      ],
      "metadata": {
        "id": "pmd0tI5gsyA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Ce qui vous sera (certainement) utile\n",
        "\n",
        "Dans cette section, nous proposons de comprendre davantage en profondeur le fonctionnement d'Autograd afin d'effectuer la différentiation automatique. Pour développer notre intuition, nous délaisserons les réseaux de neurones et travaillerons plutôt avec un ensemble restreint de fonctions."
      ],
      "metadata": {
        "id": "Jf6Q4cv-lm4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialisation et attribut**: Dans un premier temps, nous initialisons deux vecteurs de paramètres, soit $\\mathbf{a}$ et $\\mathbf{b}$, pour lesquels nous voulons calculer leur gradient."
      ],
      "metadata": {
        "id": "mp1iyLxPuRD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "FB4hQbXnuYeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fonction simple**: Nous définissons une variable $\\mathbf{c}$ laquelle est définie en fonction des vecteurs $\\mathbf{a}$ et $\\mathbf{b}$ ainsi:\n",
        "\n",
        "$$ \\mathbf{c} = 3 \\mathbf{a}^2 - \\mathbf{b}$$."
      ],
      "metadata": {
        "id": "F138C9Ouubs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = 3 * a**2 - b"
      ],
      "metadata": {
        "id": "LccJjwqdvTo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calcul du gradient de façon analytique**: De façon similaire à ce que nous avons présenté à la section précédente, supposons que $\\mathbf{c}$ est l'erreur. Afin d'estimer les paramètres du réseau de neurones, soit $\\mathbf{a}$ et $\\mathbf{b}$, nous devons calculer les dérivées partielles de $\\mathbf{c}$ en fonction des paramètres:\n",
        "\n",
        "$$ \\frac{d \\mathbf{c}}{d \\mathbf{a}} = 6 \\mathbf{a}, \\qquad \\frac{d \\mathbf{c}}{d \\mathbf{b}} = -1.$$\n",
        "\n",
        "**Calcul du gradient avec Autograd**: Nous pouvons calculer les expressions ci-haut simplement à l'aide de la commande .backward().\n"
      ],
      "metadata": {
        "id": "Wr9-meMuvYcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c.sum().backward()"
      ],
      "metadata": {
        "id": "N1FShoD_vYme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et c'est heureux que les valeurs obtenues concordent avec celles dérivées formellement:"
      ],
      "metadata": {
        "id": "h4rxCCiLzfoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(6 * a == a.grad)\n",
        "print(-1 == b.grad)"
      ],
      "metadata": {
        "id": "WZG07Wp_yk7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Quelles valeurs aurions-nous obtenues si nous avions décidé, lors de l'initialisation du vecteur $\\mathbf{a}$, de ne pas calculer le gradient pour ce vecteur de paramètres?"
      ],
      "metadata": {
        "id": "ljh4y_TDvYux"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTSqw4muM7xC"
      },
      "source": [
        "#5.0 Classifieur linéaire\n",
        "\n",
        "Dans cette section, nous allons entraîner un classifieur linéaire plutôt naïf sur le célèbre jeu de données [Iris](https://fr.wikipedia.org/wiki/Iris_de_Fisher). L'idée n'est pas d'utiliser des modèles sophistiqués, mais de simplement se faire tranquillement la main sur les concepts de différentiation automtique vus jusqu'à présent."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importatation des bibliothèques**"
      ],
      "metadata": {
        "id": "6YwRO2BF76xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "g7HsPpuB5noE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Préparation des données**"
      ],
      "metadata": {
        "id": "6LrU-aus8AqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importation des donnes\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# creation des ensemble d'entrainement et de test\n",
        "# toujours une bonne idee de brasser la soupe avant de commencer #shuffle\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "kf.get_n_splits(y)\n",
        "\n",
        "for train_index, test_index in kf.split(y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# transformation des donnees sous la forme de tenseur\n",
        "X_train, X_test = torch.Tensor(X_train), torch.Tensor(X_test)\n",
        "y_train, y_test = torch.Tensor(y_train), torch.Tensor(y_test)"
      ],
      "metadata": {
        "id": "4izyvOC_4kJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Un modèle**\n",
        "\n",
        "Dans ce cas-ci, nous allons supposer que les issues suivent le modèle suivant:\n",
        "\n",
        "$$ y = \\beta_0 x_0 + \\beta_1 x_1 + \\epsilon,$$\n",
        "où $\\epsilon \\sim N(0, 1)$. Évidemment, cette modélisation n'est pas appropriée (comprenez-vous pourquoi?), mais elle fera le boulot pour la suite de l'exemple. \n",
        "\n",
        "Nous pouvons dès lors initialiser notre modèle avec une classe plutôt simple.Enfin, comprendre comment créer une classe en Python est fondamental pour créer des modèles plus complexes. Assurez-vous de bien comprendre ce concept."
      ],
      "metadata": {
        "id": "j-cmUkxc8xyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model():\n",
        "  def __init__(self):\n",
        "    self.params = torch.tensor([[0.], [0.]], requires_grad=True)\n",
        "  \n",
        "  def prediction(self, X):\n",
        "    return(torch.mm(X, self.params).squeeze_())"
      ],
      "metadata": {
        "id": "EBsMgQDD4kVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "1. Que pensez-vous de l'initialisation des paramètres du modèle. Est-ce un problème dans ce cas-ci? \n",
        "2.Pouvez-vous imaginer un cas d'espèce où ce genre d'initalisation ne serait pas souhaitable?"
      ],
      "metadata": {
        "id": "2wkU1h3BASdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialisation**\n",
        "\n",
        "Nous initialisons par la suite le modèle et définissons les hyper paramètres."
      ],
      "metadata": {
        "id": "s5HWqNKZAKbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl = model()   # initialisation du modele\n",
        "mse = nn.MSELoss()   # fonction de perte choisie\n",
        "\n",
        "# Quelques hyper paramètres\n",
        "lr = 1e-2   # pas d'apprentissage\n",
        "nb_epoch = int(1e2)   # nombre d'epoques"
      ],
      "metadata": {
        "id": "5fDwX4d13OQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apprentissage**\n",
        "\n",
        "La phase d'entraînement se fait de façon analogue à ce que nous avons vu à la Section."
      ],
      "metadata": {
        "id": "94abzXsOIgHl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9OOBLiOY1BB"
      },
      "source": [
        "mse_train, mse_test = [], []\n",
        "\n",
        "# Apprentissage\n",
        "for epoch in range(nb_epoch):\n",
        "  \n",
        "  # Prediction (voir le module mm dans Pytorch)\n",
        "  y_hat = cl.prediction(X_train)\n",
        "\n",
        "  # Calcul de la fonction de perte (EQM dans ce cas-ci)\n",
        "  loss = mse(y_hat, y_train)\n",
        "  mse_train.append(loss)   # pratique pour un graphe futur\n",
        " \n",
        "  # Calcul du gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # Mise a jour des parametres du modele\n",
        "  cl.params.data = cl.params.data - lr * cl.params.grad\n",
        "  cl.params.grad.zero_()\n",
        "\n",
        "  mse_test.append(mse(y_test, cl.prediction(X_test)))   # pour un graphe futur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, nous pouvons étudier rapidement comment le modèle se comporte au fil des itérations à l'aide d'un petit graphique."
      ],
      "metadata": {
        "id": "_T_0qjEZI9si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mse_train, label= 'Entraînement')\n",
        "plt.plot(mse_test, label= 'Test')\n",
        "\n",
        "plt.xlabel('Epoques')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "fKFQ5CYgLRQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "1. Est-ce que les courbes ci-haut se comportent de façon attendue?\n",
        "2. Comment pourrions-nous fixer ce \"problème\"?"
      ],
      "metadata": {
        "id": "QqRfQM4KQ9xZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwuVVhsqRbGp"
      },
      "source": [
        "#6.0 MLP en Pytorch et Skorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGAG7UbRw0-"
      },
      "source": [
        "Dans cette section, nous proposons d'implémenter et entraîner un MLP sur le jeu de donnée [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST). Ce jeu de données est fameux et consiste à classer des images des chifres manuscrits.\n",
        "\n",
        "**Téléchargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8V13Q9QRkY3"
      },
      "source": [
        "train = torchvision.datasets.MNIST(\"./data\", train=True, download=True)\n",
        "test = torchvision.datasets.MNIST(\"./data\", train=False, download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKY8i-9Ss84"
      },
      "source": [
        "**Visualisation des données**\n",
        "\n",
        "Afin d'avoir une petite idée du jeu de données en question, nous pouvons visualiser quelques images en entrée à l'aide de notre fonction maison plot_mnist.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mnist(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])"
      ],
      "metadata": {
        "id": "gnUYrp4sU4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egUTRNA5S_gQ"
      },
      "source": [
        "train.labels = [train.classes[target] for target in train.targets]\n",
        "plot_mnist(train.data, train.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQXSiqhdS_It"
      },
      "source": [
        "**Construction de la classe MLP**\n",
        "\n",
        "Nous pouvons construire le MLP à l'aide de la classe suivante. Si vous êtes un peu confus.es, ne vous inquiétez pas; ce genre de manipulation deviendra rapidement une seconde nature avec un peu d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToHnu6quUUYD"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "    super(MLP, self).__init__()\n",
        "    \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, images):\n",
        "    x = images.flatten(1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.softmax(self.fc2(x), dim=-1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La classe construite, nous pouvons initialiser notre modèle."
      ],
      "metadata": {
        "id": "VZI--VxtTMMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))"
      ],
      "metadata": {
        "id": "ToPDlp4CTMc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXW7M_JgWdHQ"
      },
      "source": [
        "**Skorch**\n",
        "\n",
        "Dans ce tutoriel, l'entraînement des modèles va se faire à l'aide de [Skorch](https://skorch.readthedocs.io/en/stable/index.html). Cette bibliothèque permet entres autres d'utiliser des modèles implémentés en Pytorch et d'effectuer l'entraînement à l'aide de [Scikit-learn](https://scikit-learn.org/stable/). La phase d'entraînement du MLP diffère donc beaucoup de celle que nous avons présenté à la section précédente, où la mécanique d'Autograd était beaucoup plus explicite. Même si l'interfarce de Skorch est beaucoup plus convivial, je vous encore fortement à comprendre et saisir les nuances présentées à la Section 6."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U skorch"
      ],
      "metadata": {
        "id": "jUdUDx9yRZDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skorch"
      ],
      "metadata": {
        "id": "Jm68y7m1RbkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous faisons la migration du MLP en Skortch et fixons les hyper paramètres associés."
      ],
      "metadata": {
        "id": "zCZMLxuaVBlD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nxm2ibVEW1"
      },
      "source": [
        "# Hyper paramètres\n",
        "num_epoch = 20\n",
        "lr = 1e-2\n",
        "\n",
        "# Migration en skorch\n",
        "model = skorch.NeuralNetClassifier(mlp, max_epochs=num_epoch, lr=lr, device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entraînement à l'aide de Skorch**\n",
        "\n",
        "La phase d'entraînement avec Skorch présente automatique les performances de prédiction pour chacune des époques. Une fonction de perte (*loss*) plus faible est préférable et une capacité prédictive (*acc*) plus grande est souhaitable."
      ],
      "metadata": {
        "id": "1Vux2_zkTD2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = model.fit(train.data / 255.0, train.targets)"
      ],
      "metadata": {
        "id": "XZwD13ihTING"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFG284ipX8fr"
      },
      "source": [
        "Nous pouvons calculer l'erreur de prédiction sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNSoOvJYEGF"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test.mlp_predictions = model.predict(test.data / 255.0)\n",
        "sklearn.metrics.accuracy_score(test.targets, test.mlp_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb33PuLLYTFy"
      },
      "source": [
        "Bon, ce n'est pas fameux... C'est possible d'obtenir de bonnes performances à l'aide d'un MLP. Par contre, cela demande un peu de travail.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "1. Modifier la classe du MLP pour augmenter sa capacité, changer les fonctions d'activations, bref, tout ce qui vous passe par la tête afin d'améliorer les capacités prédictives du modèle.\n",
        "\n",
        "2. Opter pour [une autre technique](https://pytorch.org/docs/stable/optim.html#algorithms) afin d'estimer le gradient peut s'avérer, entre autres stratégies, une bonne idée. Voici un exemple ci-bas montrant comment procéder. Familiarisez-vous avec pareille manipulation et essayez d'obtenir une capacité prédicitve de plus de 96% sur l'ensemble de test."
      ],
      "metadata": {
        "id": "ogVd06lTgp-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim   # cette bibliothque propose une pletarde d'optimiseurs\n",
        "\n",
        "# initalisation du modele\n",
        "mlp = MLP(\n",
        "    input_dim=train.data.shape[1] * train.data.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=len(train.classes))\n",
        "\n",
        "# migration sur Skorch mais avec un nouvel optimiseur\n",
        "model = skorch.NeuralNetClassifier(mlp, optimizer=optim.RMSprop, max_epochs=10,\n",
        "                                   lr=1e-4, device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "model.fit(train.data / 255.0, train.targets)\n",
        "\n",
        "# predictions sur l'ensemble de test\n",
        "test.mlp_predictions = model.predict(test.data / 255.0)\n",
        "test_acc = sklearn.metrics.accuracy_score(test.targets, test.mlp_predictions)\n",
        "\n",
        "print(\"\\n Peformances sur l'ensemble de test: \", test_acc)"
      ],
      "metadata": {
        "id": "qMwMfxCmhM4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sauvegarde du modèle**\n",
        "\n",
        "Enfin, c'est une bonne idée de sauvegarder notre modèle à la suite de l'entraînement.\n"
      ],
      "metadata": {
        "id": "AlX_CD8uglrk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bip_3kAmY3LG"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"MLP.pkl\", \"wb\") as fout:\n",
        "  pickle.dump(model, fout)\n",
        "with open(\"MLP.pkl\", \"rb\") as fin:\n",
        "  model = pickle.load(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yuRqq0-ZK7H"
      },
      "source": [
        "# 7.0 CNN en Pytorch et Skorch\n",
        "\n",
        "Souvent, utiliser des modèles déjà implémentés peut s'avérer une très bonne idée. Cela sauve beaucoup de temps, entre autres choses... Heureusement, il existe plusieurs modèles classiques de CNN déjà implémentés dans la bibliothèque `torchvision`.\n",
        "\n",
        "Dans cette section, nous allons utiliser le modèle ResNet-18 (!). Puisque ce modèle a été implémenté pour classer mille types d'images, nous allons simplement réécrire la dernière couche cachée pour l'adapter au jeu de données MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEvxTOmBZnBh"
      },
      "source": [
        "resnet18 = torchvision.models.resnet18()\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))   # overide de la sortie pour l'adapter à MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVYr-2FEbH9P"
      },
      "source": [
        "Encore une fois, puisque ResNet a été implémenté pour traiter des images colorées, nous allons réécrire les images MNIST sous la forme d'un tenseur comportant trois canaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5xhvVEfbWhl"
      },
      "source": [
        "train.color_data = train.data.unsqueeze(1).expand(-1, 3, -1, -1)\n",
        "test.color_data = test.data.unsqueeze(1).expand(-1, 3, -1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCCXNrEUfDXl"
      },
      "source": [
        "Comme à la section précédente, nous initialisons notre modèle et l'entrainons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnMilF8cfWGr"
      },
      "source": [
        "# hyper parametres\n",
        "num_epoch = 2\n",
        "lr = 1e-1\n",
        "\n",
        "# initialisation\n",
        "resnet = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=num_epoch, lr=lr,\n",
        "    device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "training = resnet.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KVGjdZVNwmg"
      },
      "source": [
        "Sans surprise, et avec très peu d'effort, ResNet écrase notre MLP un peu vanille..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZomzNBiLqN"
      },
      "source": [
        "**Modèle pré entraînées** \n",
        "\n",
        "La bibliothèque `torchvision` [propose des modèles pré entraînés](https://pytorch.org/docs/stable/torchvision/models.html) sur des jeux de données distincts. Par exemple, dans ce cas-ci, le ResNet que nous allons téléchargé a été entraîné sur ImageNet. Initialiser notre modèle avec ce genre de paramètres peut s'avérer une bonne stratégie.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18-eQwAYijhA"
      },
      "source": [
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, len(train.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B20vHsLzbfRR"
      },
      "source": [
        "# migration vers Skorch\n",
        "resnet = skorch.NeuralNetClassifier(\n",
        "    resnet18, criterion=torch.nn.CrossEntropyLoss, max_epochs=num_epoch, lr=lr,\n",
        "    device=\"cuda\")\n",
        "\n",
        "# entrainement\n",
        "training = resnet.fit(train.color_data / 255.0, train.targets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}